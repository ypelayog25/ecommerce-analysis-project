name: Update Dataset and Run Analysis

on:
  schedule:
    - cron: "0 0 * * *" # Runs daily at midnight UTC
  workflow_dispatch:
    inputs:
      FORCE_RUN:
        description: "Force full analysis (ignore hash check)"
        required: false
        default: "false"

jobs:
  update-and-analyze:
    runs-on: ubuntu-latest

    env:
      KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
      KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      FORCE_RUN: ${{ github.event.inputs.FORCE_RUN }}

    steps:
      - name: ✅ Checkout Repository
        uses: actions/checkout@v3
        with:
          lfs: true

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: 📦 Install Required Libraries
        run: |
          pip install kaggle pandas matplotlib duckdb pyarrow

      - name: 🔑 Configure Kaggle Credentials
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\", \"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: 📥 Ensure raw data folder exists
        run: mkdir -p data/raw

      - name: 🔍 Download dataset metadata
        run: kaggle datasets metadata nabihazahid/ecommerce-dataset-for-sql-analysis -p data/raw

      - name: 🔍 Detect dataset changes (hash check)
        id: hash-check
        run: |
          cd data/raw
          if [ ! -f dataset-metadata.json ]; then
            echo "❌ dataset-metadata.json not found after metadata fetch."
            exit 1
          fi

          NEW_HASH=$(sha256sum dataset-metadata.json | cut -d " " -f1)
          echo "NEW_HASH=$NEW_HASH"

          if [ -f .dataset_hash.txt ]; then
            OLD_HASH=$(cat .dataset_hash.txt)
          else
            OLD_HASH=""
          fi

          echo "OLD_HASH=$OLD_HASH"

          if [[ "$FORCE_RUN" == "true" ]]; then
            echo "⚠️ FORCE_RUN enabled — analysis will run regardless of hash."
            echo "true" > ../_run_flag.txt
          elif [[ "$OLD_HASH" != "$NEW_HASH" ]]; then
            echo "✅ New dataset detected — analysis will run."
            echo "$NEW_HASH" > .dataset_hash.txt
            echo "true" > ../_run_flag.txt
          else
            echo "⚪ No dataset changes detected — skipping analysis."
            echo "false" > ../_run_flag.txt
          fi

      - name: 📦 Download dataset if changed
        if: always()
        run: |
          if [[ $(cat data/_run_flag.txt) == "true" ]]; then
            kaggle datasets download -d nabihazahid/ecommerce-dataset-for-sql-analysis -p data/raw --unzip
          fi

      - name: 🚀 Run analysis script
        if: always()
        run: |
          if [[ $(cat data/_run_flag.txt) == "true" ]]; then
            echo "Running analysis..."
            python src/step5_analysis_sql.py
          else
            echo "Skipping analysis."
          fi

      - name: 💾 Commit and push updates
        if: always()
        run: |
          if [[ $(cat data/_run_flag.txt) == "true" ]]; then
            git config user.name "GitHub Actions"
            git config user.email "actions@github.com"
            git add data/raw/.dataset_hash.txt reports/
            git commit -m "chore: update reports after dataset analysis" || echo "No changes to commit"
            git push || echo "Nothing to push"
          else
            echo "No commit needed."
          fi
