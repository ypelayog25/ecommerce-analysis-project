name: Update Dataset and Run Analysis

on:
  schedule:
    # Ejecuta todos los d√≠as a medianoche UTC
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  update-and-analyze:
    runs-on: ubuntu-latest

    steps:
      # 1Ô∏è‚É£ Clonar repo
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: false  # Para poder hacer push con token

      # 2Ô∏è‚É£ Configurar Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3Ô∏è‚É£ Instalar dependencias
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install kaggle pandas numpy matplotlib seaborn tableau-api-lib jq

      # 4Ô∏è‚É£ Configurar Kaggle API
      - name: Setup Kaggle API
        run: |
          mkdir -p ~/.kaggle
          echo "${{ secrets.KAGGLE_JSON }}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      # 5Ô∏è‚É£ Comprobar si el dataset tiene actualizaci√≥n
      - name: Check for dataset update
        id: check_update
        run: |
          kaggle datasets metadata nabihazahid/ecommerce-dataset-for-sql-analysis > data/raw/metadata.json
          latest_hash=$(jq -r '.lastUpdated' data/raw/metadata.json)
          if [ -f data/raw/.dataset_hash.txt ]; then
            old_hash=$(cat data/raw/.dataset_hash.txt)
          else
            old_hash=""
          fi
          echo "LATEST_HASH=$latest_hash" >> $GITHUB_ENV
          echo "OLD_HASH=$old_hash" >> $GITHUB_ENV
          if [ "$latest_hash" = "$old_hash" ]; then
            echo "Dataset is up to date. Skipping download and analysis."
            exit 0

      # 6Ô∏è‚É£ Descargar dataset si hay actualizaci√≥n
      - name: Download dataset from Kaggle
        if: steps.check_update.outcome != 'success'
        run: |
          kaggle datasets download -d nabihazahid/ecommerce-dataset-for-sql-analysis -p ./data/raw --unzip

      # 7Ô∏è‚É£ Actualizar hash del dataset
      - name: Update dataset hash
        if: steps.check_update.outcome != 'success'
        run: |
          echo "${{ env.LATEST_HASH }}" > data/raw/.dataset_hash.txt

      # 8Ô∏è‚É£ Ejecutar pipeline de an√°lisis
      - name: Run analysis script
        if: steps.check_update.outcome != 'success'
        run: |
          python src/analysis_pipeline.py

      # 9Ô∏è‚É£ Commit y push de resultados versionados y CSVs para Tableau Public
      - name: Commit and push versioned results
        if: steps.check_update.outcome != 'success'
        run: |
          git config --global user.name "Yenismara Pelayo Garcia"
          git config --global user.email "ypelayog25@gmail.com"
          git add data/processed reports/ data/tableau_public/
          git commit -m "chore: add versioned analysis results and CSVs for Tableau Public"
          git push https://$GITHUB_TOKEN@github.com/ypelayog25/ecommerce-analysis-project.git main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # üîü Notificaci√≥n por Slack
      - name: Send Slack notification
        if: steps.check_update.outcome != 'success'
        uses: rtCamp/action-slack-notify@v2
        with:
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
          msg: "‚úÖ Ecommerce dataset updated and analysis pipeline completed successfully."
