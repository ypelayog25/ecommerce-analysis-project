name: Update Dataset and Run Analysis

on:
  workflow_dispatch:
    inputs:
      FORCE_RUN:
        description: "Forzar anÃ¡lisis completo (ignorar hash)"
        required: false
        default: "true"
  schedule:
    - cron: "0 0 * * *"  # Ejecuta diariamente a medianoche UTC (modo automÃ¡tico)

jobs:
  update-and-analyze:
    runs-on: ubuntu-latest

    env:
      KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
      KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      FORCE_RUN: ${{ github.event.inputs.FORCE_RUN }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          lfs: true

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Kaggle and requirements
        run: |
          pip install kaggle pandas matplotlib pyarrow

      - name: Configure Kaggle
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\", \"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Ensure raw data folder exists
        run: mkdir -p data/raw

      - name: Download dataset metadata
        run: kaggle datasets metadata nabihazahid/ecommerce-dataset-for-sql-analysis -p data/raw

      - name: Detect dataset changes
        id: hash-check
        run: |
          cd data/raw
          if [ -f dataset-metadata.json ]; then
            NEW_HASH=$(sha256sum dataset-metadata.json | cut -d " " -f1)
          else
            echo "âŒ ERROR: dataset-metadata.json no encontrado"
            exit 1
          fi

          if [ -f .dataset_hash.txt ]; then
            OLD_HASH=$(cat .dataset_hash.txt)
          else
            OLD_HASH=""
          fi

          echo "OLD_HASH=$OLD_HASH"
          echo "NEW_HASH=$NEW_HASH"

          if [[ "$FORCE_RUN" == "true" ]]; then
            echo "âš ï¸ Modo PRUEBA activado: Ignorando hash y forzando anÃ¡lisis"
            echo "::set-output name=changed::true"
          elif [[ "$OLD_HASH" != "$NEW_HASH" ]]; then
            echo "âœ… Cambios detectados en dataset"
            echo "$NEW_HASH" > .dataset_hash.txt
            echo "::set-output name=changed::true"
          else
            echo "âšª No hay cambios detectados en dataset"
            echo "::set-output name=changed::false"
          fi

      - name: Download dataset if changed
        if: steps.hash-check.outputs.changed == 'true'
        run: kaggle datasets download -d nabihazahid/ecommerce-dataset-for-sql-analysis -p data/raw --unzip

      - name: Run analysis script
        if: steps.hash-check.outputs.changed == 'true'
        run: |
          echo "ðŸš€ Ejecutando anÃ¡lisis completo..."
          python src/data/step5_analysis_sql.py

      - name: Commit and push new hash & reports
        if: steps.hash-check.outputs.changed == 'true'
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data/raw/.dataset_hash.txt reports/
          git commit -m "chore: update reports after dataset analysis"
          git push
