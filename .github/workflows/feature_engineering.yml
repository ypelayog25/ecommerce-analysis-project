name: Feature Engineering & Dataset Preparation

on:
  push:
    branches:
      - main
    paths:
      - "data/raw/**"
      - "src/features/**"
      - "src/data/**"
  workflow_dispatch:

jobs:
  feature-engineering:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout repo con LFS
      - name: ✅ Checkout repository
        uses: actions/checkout@v3
        with:
          lfs: true

      # 2️⃣ Instalar Git LFS y descargar archivos grandes
      - name: 🛠 Install Git LFS and pull large files
        run: |
          sudo apt-get update
          sudo apt-get install -y git-lfs
          git lfs install
          git lfs pull

      # 3️⃣ Setup Python
      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      # 4️⃣ Instalar dependencias
      - name: 📦 Install required dependencies
        run: pip install -r requirements.txt plotly kaleido pandas

      # 5️⃣ Verificar CSV
      - name: 🔍 Verify CSV exists
        run: |
          CSV="data/processed/ecommerce_dataset_10000_cleaned.csv"
          if [ ! -f "$CSV" ]; then
            echo "❌ CSV not found. Make sure it's committed via LFS."
            exit 1
          fi
          echo "✅ CSV found: $CSV - Preview:"
          head -n 5 "$CSV"

      # 6️⃣ Ejecutar Feature Engineering
      - name: 🚀 Running Feature Engineering (create_features.py)
        run: python src/features/create_features.py

      # 7️⃣ Verificar outputs generados
      - name: 📁 Verify generated outputs
        run: |
          echo "🔍 Checking processed outputs..."
          ls -lh data/processed || echo "⚠ No processed directory found."
          if [ -f "data/processed/ecommerce_dataset_features.csv" ]; then
            echo "✅ Features CSV successfully generated."
          else
            echo "❌ Features CSV missing - check create_features.py"
            exit 1
          fi
          if [ -f "data/processed/ecommerce_dataset_features.parquet" ]; then
            echo "✅ Features Parquet successfully generated."
          else
            echo "⚠ Parquet missing - but CSV exists, workflow continues."
          fi

      # 8️⃣ Commit y push solo si hay cambios
      - name: 💾 Commit processed dataset updates (if any)
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data/processed/
          if git diff --staged --quiet; then
            echo "ℹ️ No changes to commit in processed data."
          else
            git commit -m "feat: automated feature engineering output update"
            git push origin main
            echo "✅ Processed dataset updated and committed."
